{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgUG4iLjSFET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "75dda0b5-007d-4fe6-88a5-dc0e34f45685"
      },
      "source": [
        "!pip install Medpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Medpy in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Medpy) (1.4.1)\n",
            "Requirement already satisfied: SimpleITK>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Medpy) (1.2.4)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from Medpy) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilzg2yeaTFdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import os\n",
        "import numpy as np\n",
        "from medpy.io import load, save\n",
        "import nibabel\n",
        "from keras import backend as K\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.layers import Add, Concatenate, Multiply, Reshape, Dense\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam, Nadam\n",
        "from skimage.transform import resize\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import recall_score, precision_score\n",
        "import cv2\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "image_rows = 256\n",
        "image_cols = 256\n",
        "smooth = 1.\n",
        "# Download the weight and adjust the path accordingly\n",
        "weight_path = \"/content/drive/My Drive/3DIRCAD-Result/weight/weights.100-0.01.h5\"\n",
        "\n",
        "K.set_image_data_format('channels_last') \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlM7W9CFVNt_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "90c60860-d262-4f51-d517-9e9e852ea069"
      },
      "source": [
        "#-----Create folders-----\n",
        "# Original test folder, this is where original 3DIRCAD dataset is put.\n",
        "testing_folder = '/content/drive/My Drive/3DIRCAD/Data'\n",
        "# After 3DIRCAD dataset is processed, it is saved here.\n",
        "processed_testing_folder = '/content/drive/My Drive/3DIRCAD-Preprocessed-test'\n",
        "# This is where 3DIRCAD dataset is transformed into numpy array file saved. \n",
        "numpy_folder = '/content/drive/My Drive/3DIRCAD-Preprocessed-test/numpy'\n",
        "\n",
        "if not os.path.exists(testing_folder):\n",
        "  print('Creat test folder')\n",
        "  os.mkdir(testing_folder)\n",
        "else:\n",
        "  print('Test folder exists')\n",
        "\n",
        "if not os.path.exists(processed_testing_folder):\n",
        "  print('Creat processed test folder')\n",
        "  os.mkdir(processed_testing_folder)\n",
        "else:\n",
        "  print('Processed test folder exists')\n",
        "\n",
        "if not os.path.exists(numpy_folder):\n",
        "  print('Creat numpy array folder')\n",
        "  os.mkdir(numpy_folder)\n",
        "else:\n",
        "  print('Numpy array folder exists')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test folder exists\n",
            "Processed test folder exists\n",
            "Creat numpy array folder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKK7LMg3SQBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "70dae360-24bd-486f-ab08-1d0bcfb6597d"
      },
      "source": [
        "# Use for truncate HU value of 3DIRCAD dataset\n",
        "def truncate_HU_value(range1, range2, img_path, save_path):\n",
        "    print(\"*** Truncating HU value to eliminate superfluous information ***\")\n",
        "    for idx in range(range1, range2):\n",
        "      # Due to the naming convention of 3DIRCAD dataset\n",
        "        if idx < 10:\n",
        "          img, img_header = load(img_path + '/ircad_e0' + str(idx) + '_orig.nii')\n",
        "          img[img < -200] = -200\n",
        "          img[img > 250] = 250\n",
        "          img = np.array(img, dtype='int16')\n",
        "          print('Saving image ' + str(idx))\n",
        "          save(img, save_path + '/' + 'cad-volume-' + str(idx) + '.nii')\n",
        "        else:\n",
        "          img, img_header = load(img_path + '/ircad_e' + str(idx) + '_orig.nii')\n",
        "          img[img < -200] = -200\n",
        "          img[img > 250] = 250\n",
        "          img = np.array(img, dtype='int16')\n",
        "          print('Saving image ' + str(idx))\n",
        "          save(img, save_path + '/' + 'cad-volume-' + str(idx) + '.nii')\n",
        "\n",
        "\n",
        "\n",
        "# Remove tumor label of 3DIRCAD dataset\n",
        "def remove_tumor_label(range1, range2, img_path, save_path):\n",
        "    print(\"*** Removing tumor label ***\")\n",
        "    for idx in range(range1, range2):\n",
        "        # Due to the naming convention of 3DIRCAD dataset\n",
        "        if idx < 10:\n",
        "          img, img_header = load(img_path + '/ircad_e0' + str(idx) + '_liver.nii')\n",
        "          img[img == 2] = 1\n",
        "          img = np.array(img, dtype='uint8')\n",
        "          print('Saving image ' + str(idx))\n",
        "          save(img, save_path + '/' + 'cad-segmentation-' + str(idx) + '.nii')\n",
        "        else:\n",
        "          img, img_header = load(img_path + '/ircad_e' + str(idx) + '_liver.nii')\n",
        "          img[img == 2] = 1\n",
        "          img = np.array(img, dtype='uint8')\n",
        "          print('Saving image ' + str(idx))\n",
        "          save(img, save_path + '/' + 'cad-segmentation-' + str(idx) + '.nii')\n",
        "\n",
        "\n",
        "\n",
        "truncate_HU_value(range1=1, range2=21, img_path=testing_folder, save_path=processed_testing_folder)\n",
        "remove_tumor_label(range1=1, range2=21, img_path=testing_folder, save_path=processed_testing_folder)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** Truncating HU value to eliminate superfluous information ***\n",
            "Saving image 1\n",
            "Saving image 2\n",
            "Saving image 3\n",
            "Saving image 4\n",
            "Saving image 5\n",
            "Saving image 6\n",
            "Saving image 7\n",
            "Saving image 8\n",
            "Saving image 9\n",
            "Saving image 10\n",
            "Saving image 11\n",
            "Saving image 12\n",
            "Saving image 13\n",
            "Saving image 14\n",
            "Saving image 15\n",
            "Saving image 16\n",
            "Saving image 17\n",
            "Saving image 18\n",
            "Saving image 19\n",
            "Saving image 20\n",
            "*** Removing tumor label ***\n",
            "Saving image 1\n",
            "Saving image 2\n",
            "Saving image 3\n",
            "Saving image 4\n",
            "Saving image 5\n",
            "Saving image 6\n",
            "Saving image 7\n",
            "Saving image 8\n",
            "Saving image 9\n",
            "Saving image 10\n",
            "Saving image 11\n",
            "Saving image 12\n",
            "Saving image 13\n",
            "Saving image 14\n",
            "Saving image 15\n",
            "Saving image 16\n",
            "Saving image 17\n",
            "Saving image 18\n",
            "Saving image 19\n",
            "Saving image 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czC4uL23V29m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "63a9262b-fc08-4890-c7b1-f81dcdc52d4d"
      },
      "source": [
        "def create_test_data():\n",
        "    print('-' * 30)\n",
        "    print('Creating test data...')\n",
        "    print('-' * 30)\n",
        "\n",
        "    imgs_test = []\n",
        "    masks_test = []\n",
        "    testing_images_files = []\n",
        "    testing_masks_files = []\n",
        "    \n",
        "    # List out all of the item available in the folder\n",
        "    item_list = os.listdir(testing_folder)\n",
        "    np.sort(item_list)\n",
        "    \n",
        "    # Adjust the range based on which CT scan you want to test\n",
        "    for idx in range(1,2):\n",
        "      testing_images_files.append('cad-volume-' + str(idx) + '.nii')\n",
        "      testing_masks_files.append('cad-segmentation-' + str(idx) + '.nii')\n",
        "\n",
        "    # Load up the CT scan and transformed them into arrays\n",
        "    for orig, liver in zip(testing_images_files, testing_masks_files):\n",
        "        print('Processing: ' + orig)\n",
        "        print('Processing: ' + liver)\n",
        "        testing_image = nibabel.load(os.path.join(processed_testing_folder, orig))\n",
        "        testing_mask = nibabel.load(os.path.join(processed_testing_folder, liver))\n",
        "        \n",
        "        print(\"Total testing slices before eliminate non-liver slice: \" + str(testing_image.shape[2]))\n",
        "        for k in range(testing_image.shape[2]):\n",
        "            image_2d = np.array(testing_image.get_fdata()[::2, ::2, k])\n",
        "            mask_2d = np.array(testing_mask.get_fdata()[::2, ::2, k])\n",
        "            # If you want to test with uncropped data, comment out the line below\n",
        "            if len(np.unique(mask_2d)) != 1:\n",
        "              masks_test.append(mask_2d)\n",
        "              imgs_test.append(image_2d)\n",
        "        \n",
        "    \n",
        "    print(\"Total testing slices after eliminate non-liver slice: \" + str(len(imgs_test)))\n",
        "\n",
        "    # Transform orginal array (0,1,2) into array with format (2,0,1)\n",
        "    imgst = np.ndarray((len(imgs_test), image_rows, image_cols), dtype=np.uint8)\n",
        "    maskst = np.ndarray((len(masks_test), image_rows, image_cols), dtype=np.uint8)\n",
        "\n",
        "    for index, img in enumerate(imgs_test):\n",
        "        imgst[index, :, :] = img\n",
        "\n",
        "    for index, mask in enumerate(masks_test):\n",
        "        maskst[index, :, :] = mask\n",
        "\n",
        "    np.save(numpy_folder + '/' + 'imgs_test.npy', imgst)\n",
        "    np.save(numpy_folder + '/' + 'imgs_mask.npy', maskst)\n",
        "    print('Saving to .npy files done.')\n",
        "    \n",
        "\n",
        "# Load up the numpy array\n",
        "def load_test_data():\n",
        "    print('--- Loading test images ---')\n",
        "    imgs_test = np.load(numpy_folder + '/' + 'imgs_test.npy')\n",
        "    masks_test = np.load(numpy_folder + '/' + 'imgs_mask.npy')\n",
        "    return imgs_test, masks_test\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    create_test_data()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "Creating test data...\n",
            "------------------------------\n",
            "Processing: cad-volume-1.nii\n",
            "Processing: cad-segmentation-1.nii\n",
            "Total testing slices before eliminate non-liver slice: 129\n",
            "Total testing slices after eliminate non-liver slice: 98\n",
            "Saving to .npy files done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr0s-elKYBTs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f9a1686f-c9ab-4673-8970-11a947e8eef9"
      },
      "source": [
        "# ResUNet model\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def bn_act(x, act=True):\n",
        "    x = BatchNormalization()(x)\n",
        "    if act == True:\n",
        "        x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    conv = bn_act(x)\n",
        "    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
        "    return conv\n",
        "\n",
        "\n",
        "def stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
        "\n",
        "    shortcut = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "\n",
        "    output = Add()([conv, shortcut])\n",
        "    return output\n",
        "\n",
        "\n",
        "def residual_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
        "    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n",
        "\n",
        "    shortcut = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "\n",
        "    output = Add()([shortcut, res])\n",
        "    return output\n",
        "\n",
        "\n",
        "def upsample_concat_block(x, xskip):\n",
        "    u = UpSampling2D((2, 2))(x)\n",
        "    c = Concatenate()([u, xskip])\n",
        "    return c\n",
        "\n",
        "\n",
        "def ResUNet():\n",
        "    f = [16, 32, 64, 128, 256]\n",
        "    inputs = Input((image_rows, image_cols, 1))\n",
        "\n",
        "    ## Encoder\n",
        "    e0 = inputs\n",
        "    e1 = stem(e0, f[0])\n",
        "    e2 = residual_block(e1, f[1], strides=2)\n",
        "    e3 = residual_block(e2, f[2], strides=2)\n",
        "    e4 = residual_block(e3, f[3], strides=2)\n",
        "    e5 = residual_block(e4, f[4], strides=2)\n",
        "\n",
        "    ## Bridge\n",
        "    b0 = conv_block(e5, f[4], strides=1)\n",
        "    b1 = conv_block(b0, f[4], strides=1)\n",
        "\n",
        "    ## Decoder\n",
        "    u1 = upsample_concat_block(b1, e4)\n",
        "    d1 = residual_block(u1, f[4])\n",
        "\n",
        "    u2 = upsample_concat_block(d1, e3)\n",
        "    d2 = residual_block(u2, f[3])\n",
        "\n",
        "    u3 = upsample_concat_block(d2, e2)\n",
        "    d3 = residual_block(u3, f[2])\n",
        "\n",
        "    u4 = upsample_concat_block(d3, e1)\n",
        "    d4 = residual_block(u4, f[1])\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    metrics = [dice_coef, Recall(), Precision()]\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\", metrics=metrics)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Preprocess test data by adding a new dimension in order to feed the data to network\n",
        "def preprocess(imgs):\n",
        "    print('--- Preprocessing images ---')\n",
        "    imgs_p = np.ndarray((imgs.shape[0], image_rows, image_cols), dtype=np.uint8)\n",
        "    for i in range(imgs.shape[0]):\n",
        "        imgs_p[i] = resize(imgs[i], (image_rows, image_cols), preserve_range=True)\n",
        "\n",
        "    imgs_p = imgs_p[..., np.newaxis]\n",
        "    return imgs_p\n",
        "\n",
        "\n",
        "def get_dice_coef(y_true, y_pred):\n",
        "    intersection = np.sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (np.sum(y_true) + np.sum(y_pred) + smooth)\n",
        "\n",
        "def get_recall(y_true, y_pred):\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.int32)\n",
        "    m = tf.keras.metrics.Recall()\n",
        "    m.update_state(y_true, y_pred)\n",
        "    r = m.result().numpy()\n",
        "    m.reset_states()\n",
        "    return r\n",
        "\n",
        "def get_precision(y_true, y_pred):\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.int32)\n",
        "    m = tf.keras.metrics.Precision()\n",
        "    m.update_state(y_true, y_pred)\n",
        "    r = m.result().numpy()\n",
        "    m.reset_states()\n",
        "    return r\n",
        "\n",
        "def get_metrics(y_true, y_pred):\n",
        "    y_pred = y_pred.flatten()\n",
        "    y_true = y_true.flatten()\n",
        "\n",
        "    dice_coef_val = get_dice_coef(y_true, y_pred)\n",
        "\n",
        "    y_true = y_true.astype(np.int32)\n",
        "   \n",
        "    recall_value = get_recall(y_true, y_pred)\n",
        "    precision_value = get_precision(y_true, y_pred)\n",
        "\n",
        "    return [dice_coef_val,recall_value, precision_value]\n",
        "\n",
        "\n",
        "def predict():\n",
        "    for idx in range(1):\n",
        "        print('-' * 30)\n",
        "        print('Loading model and preprocessing test data...' + str(idx))\n",
        "        print('-' * 30)\n",
        "\n",
        "        model = ResUNet()\n",
        "        model.load_weights(weight_path)\n",
        "\n",
        "        #  load 3D data\n",
        "        img_test = np.load('/content/drive/My Drive/3DIRCAD-Preprocessed-test/numpy/imgs_test.npy')\n",
        "\n",
        "        img_test = preprocess(img_test)\n",
        "        img_test = img_test.astype('float32')\n",
        "\n",
        "        mean = np.mean(img_test)  # mean for data centering\n",
        "        std = np.std(img_test)  # std for data normalization\n",
        "\n",
        "        img_test -= mean\n",
        "        img_test /= std\n",
        "\n",
        "        \n",
        "        #  load liver mask\n",
        "        mask = np.load('/content/drive/My Drive/3DIRCAD-Preprocessed-test/numpy/imgs_mask.npy')\n",
        "        mask = preprocess(mask)\n",
        "        mask = mask.astype('float32')\n",
        "        \n",
        "        print('-' * 30)\n",
        "        print('Predicting masks on test data...' + str(idx))\n",
        "        print('-' * 30)\n",
        "\n",
        "        imgs_mask_test_result = model.predict(img_test, verbose=1)\n",
        "\n",
        "        #for k in range(len(imgs_mask_test_result)):\n",
        "            #imgs_mask_test_result[k][:, :, :] = imgs_mask_test_result[k][:, ::-1, :]\n",
        "        \n",
        "        result = get_metrics(mask, imgs_mask_test_result)\n",
        "    \n",
        "        print(result)\n",
        "        \n",
        "        \n",
        "if __name__ == '__main__':\n",
        "    predict()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "Loading model and preprocessing test data...0\n",
            "------------------------------\n",
            "--- Preprocessing images ---\n",
            "--- Preprocessing images ---\n",
            "------------------------------\n",
            "Predicting masks on test data...0\n",
            "------------------------------\n",
            "4/4 [==============================] - 29s 7s/step\n",
            "[0.986997569787921, 0.98160905, 0.99244964]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}