{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict_resunetplusplus.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEswWf4nbKbv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "e0cd704e-c246-4e0a-8569-a00e25b6bb2f"
      },
      "source": [
        "!pip install Medpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Medpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/70/c1fd5dd60242eee81774696ea7ba4caafac2bad8f028bba94b1af83777d7/MedPy-0.4.0.tar.gz (151kB)\n",
            "\r\u001b[K     |██▏                             | 10kB 17.6MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 133kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 143kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Medpy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from Medpy) (1.18.5)\n",
            "Collecting SimpleITK>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d8/53338c34f71020725ffb3557846c80af96c29c03bc883551a2565aa68a7c/SimpleITK-1.2.4-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5MB 72kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: Medpy\n",
            "  Building wheel for Medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Medpy: filename=MedPy-0.4.0-cp36-cp36m-linux_x86_64.whl size=753441 sha256=51720e83c524afb27f28cff804989066ec6a5b332e6fd7ef56c03c80806085d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/c9/9c/2c6281c7a72b9fb1570862a4f028af7ce38405008354fbf870\n",
            "Successfully built Medpy\n",
            "Installing collected packages: SimpleITK, Medpy\n",
            "Successfully installed Medpy-0.4.0 SimpleITK-1.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A_gtYHBbS4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import os\n",
        "import numpy as np\n",
        "from medpy.io import load, save\n",
        "import nibabel\n",
        "from keras import backend as K\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.layers import Add, Concatenate, Multiply, Reshape, Dense\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam, SGD\n",
        "from skimage.transform import resize\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import recall_score, precision_score\n",
        "import cv2\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from keras.layers.pooling import GlobalAveragePooling2D, MaxPooling2D\n",
        "from keras.regularizers import l2\n",
        "\n",
        "image_rows = 256\n",
        "image_cols = 256\n",
        "smooth = 1.\n",
        "weight_decay = 1e-2\n",
        "# Download the weight and adjust the path accordingly\n",
        "weight_path = \"/content/drive/My Drive/3DIRCAD-Result/weight/weights-resunet++.h5\"\n",
        "\n",
        "K.set_image_data_format('channels_last')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfsGs5KxbW2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-----Create folders-----\n",
        "# Original test folder, this is where original 3DIRCAD dataset is put.\n",
        "testing_folder = '/content/drive/My Drive/3DIRCAD/Data'\n",
        "# After 3DIRCAD dataset is processed, it is saved here.\n",
        "processed_testing_folder = '/content/drive/My Drive/3DIRCAD-Preprocessed-test'\n",
        "# This is where 3DIRCAD dataset is transformed into numpy array file saved. \n",
        "numpy_folder = '/content/drive/My Drive/3DIRCAD-Preprocessed-test/numpy'\n",
        "\n",
        "if not os.path.exists(testing_folder):\n",
        "  print('Creat test folder')\n",
        "  os.mkdir(testing_folder)\n",
        "else:\n",
        "  print('Test folder exists')\n",
        "\n",
        "if not os.path.exists(processed_testing_folder):\n",
        "  print('Creat processed test folder')\n",
        "  os.mkdir(processed_testing_folder)\n",
        "else:\n",
        "  print('Processed test folder exists')\n",
        "\n",
        "if not os.path.exists(numpy_folder):\n",
        "  print('Creat numpy array folder')\n",
        "  os.mkdir(numpy_folder)\n",
        "else:\n",
        "  print('Numpy array folder exists')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKtXSLaDbj5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use for truncate HU value of 3DIRCAD dataset\n",
        "def truncate_HU_value(range1, range2, img_path, save_path):\n",
        "    print(\"*** Truncating HU value to eliminate superfluous information ***\")\n",
        "    for idx in range(range1, range2):\n",
        "      # Due to the naming convention of 3DIRCAD dataset\n",
        "        if idx < 10:\n",
        "          img, img_header = load(img_path + '/ircad_e0' + str(idx) + '_orig.nii')\n",
        "          img[img < -200] = -200\n",
        "          img[img > 250] = 250\n",
        "          img = np.array(img, dtype='int16')\n",
        "          print('Saving image ' + str(idx))\n",
        "          save(img, save_path + '/' + 'cad-volume-' + str(idx) + '.nii')\n",
        "        else:\n",
        "          img, img_header = load(img_path + '/ircad_e' + str(idx) + '_orig.nii')\n",
        "          img[img < -200] = -200\n",
        "          img[img > 250] = 250\n",
        "          img = np.array(img, dtype='int16')\n",
        "          print('Saving image ' + str(idx))\n",
        "          save(img, save_path + '/' + 'cad-volume-' + str(idx) + '.nii')\n",
        "\n",
        "\n",
        "\n",
        "# Remove tumor label of 3DIRCAD dataset\n",
        "def remove_tumor_label(range1, range2, img_path, save_path):\n",
        "    print(\"*** Removing tumor label ***\")\n",
        "    for idx in range(range1, range2):\n",
        "        # Due to the naming convention of 3DIRCAD dataset\n",
        "        if idx < 10:\n",
        "          img, img_header = load(img_path + '/ircad_e0' + str(idx) + '_liver.nii')\n",
        "          img[img == 2] = 1\n",
        "          img = np.array(img, dtype='uint8')\n",
        "          print('Saving image ' + str(idx))\n",
        "          save(img, save_path + '/' + 'cad-segmentation-' + str(idx) + '.nii')\n",
        "        else:\n",
        "          img, img_header = load(img_path + '/ircad_e' + str(idx) + '_liver.nii')\n",
        "          img[img == 2] = 1\n",
        "          img = np.array(img, dtype='uint8')\n",
        "          print('Saving image ' + str(idx))\n",
        "          save(img, save_path + '/' + 'cad-segmentation-' + str(idx) + '.nii')\n",
        "\n",
        "\n",
        "\n",
        "truncate_HU_value(range1=1, range2=21, img_path=testing_folder, save_path=processed_testing_folder)\n",
        "remove_tumor_label(range1=1, range2=21, img_path=testing_folder, save_path=processed_testing_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Juc_XIpXbnGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_test_data():\n",
        "    print('-' * 30)\n",
        "    print('Creating test data...')\n",
        "    print('-' * 30)\n",
        "\n",
        "    imgs_test = []\n",
        "    masks_test = []\n",
        "    testing_images_files = []\n",
        "    testing_masks_files = []\n",
        "    \n",
        "    # List out all of the item available in the folder\n",
        "    item_list = os.listdir(testing_folder)\n",
        "    np.sort(item_list)\n",
        "    \n",
        "    # Adjust the range based on which CT scan you want to test\n",
        "    for idx in range(1,2):\n",
        "      testing_images_files.append('cad-volume-' + str(idx) + '.nii')\n",
        "      testing_masks_files.append('cad-segmentation-' + str(idx) + '.nii')\n",
        "\n",
        "    # Load up the CT scan and transformed them into arrays\n",
        "    for orig, liver in zip(testing_images_files, testing_masks_files):\n",
        "        print('Processing: ' + orig)\n",
        "        print('Processing: ' + liver)\n",
        "        testing_image = nibabel.load(os.path.join(processed_testing_folder, orig))\n",
        "        testing_mask = nibabel.load(os.path.join(processed_testing_folder, liver))\n",
        "        \n",
        "        print(\"Total testing slices before eliminate non-liver slice: \" + str(testing_image.shape[2]))\n",
        "        for k in range(testing_image.shape[2]):\n",
        "            image_2d = np.array(testing_image.get_fdata()[::2, ::2, k])\n",
        "            mask_2d = np.array(testing_mask.get_fdata()[::2, ::2, k])\n",
        "            # If you want to test with uncropped data, comment out the line below\n",
        "            if len(np.unique(mask_2d)) != 1:\n",
        "              masks_test.append(mask_2d)\n",
        "              imgs_test.append(image_2d)\n",
        "        \n",
        "    \n",
        "    print(\"Total testing slices after eliminate non-liver slice: \" + str(len(imgs_test)))\n",
        "\n",
        "    # Transform orginal array (0,1,2) into array with format (2,0,1)\n",
        "    imgst = np.ndarray((len(imgs_test), image_rows, image_cols), dtype=np.uint8)\n",
        "    maskst = np.ndarray((len(masks_test), image_rows, image_cols), dtype=np.uint8)\n",
        "\n",
        "    for index, img in enumerate(imgs_test):\n",
        "        imgst[index, :, :] = img\n",
        "\n",
        "    for index, mask in enumerate(masks_test):\n",
        "        maskst[index, :, :] = mask\n",
        "\n",
        "    np.save(numpy_folder + '/' + 'imgs_test.npy', imgst)\n",
        "    np.save(numpy_folder + '/' + 'imgs_mask.npy', maskst)\n",
        "    print('Saving to .npy files done.')\n",
        "    \n",
        "\n",
        "# Load up the numpy array\n",
        "def load_test_data():\n",
        "    print('--- Loading test images ---')\n",
        "    imgs_test = np.load(numpy_folder + '/' + 'imgs_test.npy')\n",
        "    masks_test = np.load(numpy_folder + '/' + 'imgs_mask.npy')\n",
        "    return imgs_test, masks_test\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    create_test_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcpoqxnibsFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "561c4079-d47e-48a6-dc2b-5ca24495b08f"
      },
      "source": [
        "\"\"\"\n",
        "- Author DebeshJha\n",
        "- Link https://github.com/DebeshJha/ResUNetplusplus_with-CRF-and-TTA\n",
        "\"\"\"\n",
        "\n",
        "# ResUNet++ model\n",
        "def squeeze_excite_block(inputs, ratio=8):\n",
        "    init = inputs\n",
        "    channel_axis = -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "\n",
        "    x = Multiply()([init, se])\n",
        "    return x\n",
        "\n",
        "\n",
        "def stem_block(x, n_filter, strides):\n",
        "    x_init = x\n",
        "\n",
        "    ## Conv 1\n",
        "    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=strides, kernel_regularizer=l2(weight_decay))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(n_filter, (3, 3), padding=\"same\", kernel_regularizer=l2(weight_decay))(x)\n",
        "\n",
        "    ## Shortcut\n",
        "    s = Conv2D(n_filter, (1, 1), padding=\"same\", strides=strides, kernel_regularizer=l2(weight_decay))(x_init)\n",
        "    s = BatchNormalization()(s)\n",
        "\n",
        "    ## Add\n",
        "    x = Add()([x, s])\n",
        "    x = squeeze_excite_block(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_block(x, n_filter, strides=1):\n",
        "    x_init = x\n",
        "\n",
        "    ## Conv 1\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=strides, kernel_regularizer=l2(weight_decay))(x)\n",
        "    ## Conv 2\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=1, kernel_regularizer=l2(weight_decay))(x)\n",
        "\n",
        "    ## Shortcut\n",
        "    s = Conv2D(n_filter, (1, 1), padding=\"same\", strides=strides, kernel_regularizer=l2(weight_decay))(x_init)\n",
        "    s = BatchNormalization()(s)\n",
        "\n",
        "    ## Add\n",
        "    x = Add()([x, s])\n",
        "    x = squeeze_excite_block(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def aspp_block(x, num_filters, rate_scale=1):\n",
        "    x1 = Conv2D(num_filters, (3, 3), dilation_rate=(6 * rate_scale, 6 * rate_scale), padding=\"SAME\", kernel_regularizer=l2(weight_decay))(x)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "\n",
        "    x2 = Conv2D(num_filters, (3, 3), dilation_rate=(12 * rate_scale, 12 * rate_scale), padding=\"SAME\", kernel_regularizer=l2(weight_decay))(x)\n",
        "    x2 = BatchNormalization()(x2)\n",
        "\n",
        "    x3 = Conv2D(num_filters, (3, 3), dilation_rate=(18 * rate_scale, 18 * rate_scale), padding=\"SAME\", kernel_regularizer=l2(weight_decay))(x)\n",
        "    x3 = BatchNormalization()(x3)\n",
        "\n",
        "    x4 = Conv2D(num_filters, (3, 3), padding=\"SAME\", kernel_regularizer=l2(weight_decay))(x)\n",
        "    x4 = BatchNormalization()(x4)\n",
        "\n",
        "    y = Add()([x1, x2, x3, x4])\n",
        "    y = Conv2D(num_filters, (1, 1), padding=\"SAME\", kernel_regularizer=l2(weight_decay))(y)\n",
        "    return y\n",
        "\n",
        "\n",
        "def attention_block(g, x):\n",
        "    # g: Output of Parallel Encoder block\n",
        "    # x: Output of Previous Decoder block\n",
        "\n",
        "    filters = x.shape[-1]\n",
        "\n",
        "    g_conv = BatchNormalization()(g)\n",
        "    g_conv = Activation(\"relu\")(g_conv)\n",
        "    g_conv = Conv2D(filters, (3, 3), padding=\"SAME\", kernel_regularizer=l2(weight_decay))(g_conv)\n",
        "\n",
        "    g_pool = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(g_conv)\n",
        "\n",
        "    x_conv = BatchNormalization()(x)\n",
        "    x_conv = Activation(\"relu\")(x_conv)\n",
        "    x_conv = Conv2D(filters, (3, 3), padding=\"SAME\", kernel_regularizer=l2(weight_decay))(x_conv)\n",
        "\n",
        "    gc_sum = Add()([g_pool, x_conv])\n",
        "\n",
        "    gc_conv = BatchNormalization()(gc_sum)\n",
        "    gc_conv = Activation(\"relu\")(gc_conv)\n",
        "    gc_conv = Conv2D(filters, (3, 3), padding=\"SAME\", kernel_regularizer=l2(weight_decay))(gc_conv)\n",
        "\n",
        "    gc_mul = Multiply()([gc_conv, x])\n",
        "    return gc_mul\n",
        "\n",
        "\n",
        "class ResUnetPlusPlus:\n",
        "    def __init__(self, input_size=256):\n",
        "        self.input_size = input_size\n",
        "\n",
        "    def build_model(self):\n",
        "        n_filters = [32, 64, 128, 256, 512]\n",
        "        inputs = Input((self.input_size, self.input_size, 1))\n",
        "\n",
        "        c0 = inputs\n",
        "        c1 = stem_block(c0, n_filters[0], strides=1)\n",
        "\n",
        "        ## Encoder\n",
        "        c2 = resnet_block(c1, n_filters[1], strides=2)\n",
        "        c3 = resnet_block(c2, n_filters[2], strides=2)\n",
        "        c4 = resnet_block(c3, n_filters[3], strides=2)\n",
        "\n",
        "        ## Bridge\n",
        "        b1 = aspp_block(c4, n_filters[4])\n",
        "\n",
        "        ## Decoder\n",
        "        d1 = attention_block(c3, b1)\n",
        "        d1 = UpSampling2D((2, 2))(d1)\n",
        "        d1 = Concatenate()([d1, c3])\n",
        "        d1 = resnet_block(d1, n_filters[3])\n",
        "\n",
        "        d2 = attention_block(c2, d1)\n",
        "        d2 = UpSampling2D((2, 2))(d2)\n",
        "        d2 = Concatenate()([d2, c2])\n",
        "        d2 = resnet_block(d2, n_filters[2])\n",
        "\n",
        "        d3 = attention_block(c1, d2)\n",
        "        d3 = UpSampling2D((2, 2))(d3)\n",
        "        d3 = Concatenate()([d3, c1])\n",
        "        d3 = resnet_block(d3, n_filters[1])\n",
        "\n",
        "        ## output\n",
        "        outputs = aspp_block(d3, n_filters[0])\n",
        "        outputs = Conv2D(1, (1, 1), padding=\"same\", kernel_regularizer=l2(weight_decay))(outputs)\n",
        "        outputs = Activation(\"sigmoid\")(outputs)\n",
        "\n",
        "        ## Model\n",
        "        model = Model(inputs, outputs)\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "# Preprocess test data by adding a new dimension in order to feed the data to network\n",
        "def preprocess(imgs):\n",
        "    print('--- Preprocessing images ---')\n",
        "    imgs_p = np.ndarray((imgs.shape[0], image_rows, image_cols), dtype=np.uint8)\n",
        "    for i in range(imgs.shape[0]):\n",
        "        imgs_p[i] = resize(imgs[i], (image_rows, image_cols), preserve_range=True)\n",
        "\n",
        "    imgs_p = imgs_p[..., np.newaxis]\n",
        "    return imgs_p\n",
        "\n",
        "\n",
        "def get_dice_coef(y_true, y_pred):\n",
        "    intersection = np.sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (np.sum(y_true) + np.sum(y_pred) + smooth)\n",
        "\n",
        "def get_recall(y_true, y_pred):\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.int32)\n",
        "    m = tf.keras.metrics.Recall()\n",
        "    m.update_state(y_true, y_pred)\n",
        "    r = m.result().numpy()\n",
        "    m.reset_states()\n",
        "    return r\n",
        "\n",
        "def get_precision(y_true, y_pred):\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.int32)\n",
        "    m = tf.keras.metrics.Precision()\n",
        "    m.update_state(y_true, y_pred)\n",
        "    r = m.result().numpy()\n",
        "    m.reset_states()\n",
        "    return r\n",
        "\n",
        "def get_metrics(y_true, y_pred):\n",
        "    y_pred = y_pred.flatten()\n",
        "    y_true = y_true.flatten()\n",
        "\n",
        "    dice_coef_val = get_dice_coef(y_true, y_pred)\n",
        "\n",
        "    y_true = y_true.astype(np.int32)\n",
        "   \n",
        "    recall_value = get_recall(y_true, y_pred)\n",
        "    precision_value = get_precision(y_true, y_pred)\n",
        "\n",
        "    return [dice_coef_val,recall_value, precision_value]\n",
        "\n",
        "\n",
        "def predict():\n",
        "    for idx in range(1):\n",
        "        print('-' * 30)\n",
        "        print('Loading model and preprocessing test data...' + str(idx))\n",
        "        print('-' * 30)\n",
        "\n",
        "        arch = ResUnetPlusPlus(input_size=256)\n",
        "        model = arch.build_model()\n",
        "        model.load_weights(weight_path)\n",
        "\n",
        "        optimizer = SGD(lr=1e-5, momentum=0.9, nesterov=True)\n",
        "        metrics = [get_dice_coef, Recall(), Precision()]\n",
        "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=metrics)\n",
        "\n",
        "        #  load 3D data\n",
        "        img_test = np.load('/content/drive/My Drive/3DIRCAD-Preprocessed-test/numpy/imgs_test.npy')\n",
        "\n",
        "        img_test = preprocess(img_test)\n",
        "        img_test = img_test.astype('float32')\n",
        "\n",
        "        mean = np.mean(img_test)  # mean for data centering\n",
        "        std = np.std(img_test)  # std for data normalization\n",
        "\n",
        "        img_test -= mean\n",
        "        img_test /= std\n",
        "\n",
        "        \n",
        "        #  load liver mask\n",
        "        mask = np.load('/content/drive/My Drive/3DIRCAD-Preprocessed-test/numpy/imgs_mask.npy')\n",
        "        mask = preprocess(mask)\n",
        "        mask = mask.astype('float32')\n",
        "        \n",
        "        print('-' * 30)\n",
        "        print('Predicting masks on test data...' + str(idx))\n",
        "        print('-' * 30)\n",
        "\n",
        "        imgs_mask_test_result = model.predict(img_test, verbose=1)\n",
        "\n",
        "        #for k in range(len(imgs_mask_test_result)):\n",
        "            #imgs_mask_test_result[k][:, :, :] = imgs_mask_test_result[k][:, ::-1, :]\n",
        "        \n",
        "        result = get_metrics(mask, imgs_mask_test_result)\n",
        "    \n",
        "        print(result)\n",
        "        \n",
        "        \n",
        "if __name__ == '__main__':\n",
        "    predict()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "Loading model and preprocessing test data...0\n",
            "------------------------------\n",
            "--- Preprocessing images ---\n",
            "--- Preprocessing images ---\n",
            "------------------------------\n",
            "Predicting masks on test data...0\n",
            "------------------------------\n",
            "4/4 [==============================] - 8s 2s/step\n",
            "[0.9722369373861783, 0.9738993, 0.9891086]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}